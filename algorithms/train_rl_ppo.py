import gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
import logging

from nmap_tool import nmap
from dirb_tool import dirb
from SQLmap_tool import sqlmap
from WPScan_tool import wpscan

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ToolEnv(gym.Env):
    def __init__(self):
        super(ToolEnv, self).__init__()
        logger.info("Initializing environment")
        self.action_space = gym.spaces.Discrete(4)  # 4 tools: nmap, dirb, sqlmap, wpscan
        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(1,), dtype=int)  # Just the length of output
        self.tools = [nmap("127.0.0.1"), dirb("127.0.0.1"), sqlmap("127.0.0.1"), wpscan("127.0.0.1")]
        self.current_tool_output = 0

    def reset(self):
        logger.info("Environment reset")
        return [0]

    def step(self, action):
        logger.info(f"Action chosen: {action}")
        # Choose tool based on action
        tool = self.tools[action]
        result = tool.run()
        self.current_tool_output = result if result else 0
        reward = self.current_tool_output
        done = True  # End the episode after one step
        return [self.current_tool_output], reward, done, {}

    def render(self, mode="human"):
        logger.info(f"Tool Output Length: {self.current_tool_output}")

    def close(self):
        logger.info("Environment closed")

# Create the environment
logger.info("Creating environment")
env = DummyVecEnv([lambda: ToolEnv()])

# Instantiate the agent
logger.info("Instantiating the agent")
model = PPO("MlpPolicy", env, verbose=1)

# Train the agent
logger.info("Starting training")
model.learn(total_timesteps=5000, log_interval=1)

# Save the agent
logger.info("Saving the trained agent")
model.save("tool_agent")

env.close()


